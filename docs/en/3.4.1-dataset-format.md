---
layout: page
title: Dataset Format
permalink: /docs/en/dataset-format
key: dataset-en
aside:
  toc: true
sidebar:
  nav: dataset-en
---



<head>
    <style>
        .container {
            display: flex;
            justify-content: space-between; Creates space around items
        }

        .image-with-caption {
            width: 100%;
            margin: auto;
        }

        .image-with-caption img {
            width: 100%;
            height: auto;
        }

        .image-with-caption figcaption {
            text-align: center;
        }
    </style>
</head>
<figure class="image-with-caption">
    <img src="../assets/images/save.png">
    <!-- <figcaption>Spatial Annotation</figcaption> -->
</figure>

Our **[MM-WLAuslan](https://drive.google.com/drive/folders/1EQ1Nh3lidEcu1QLFw0IjRN7YqEq1N48q?usp=sharing)** is organized into several main directories, each containing various types of data essential for training, validating, and testing in multimedia and sign language analysis projects. The detailed organization facilitates straightforward access to data types across different experimental settings, as described below:

- **Annotations**
  - *Pose* - The keypoint sequence of the signer in each sign language video.
  - *Split* - File delineating the division of data into training, validation, and test sets.
  - *Labels* - Gloss ID labels or annotations corresponding to the data samples.

- **Train**
  - *RGB* - Contains RGB videos.
  - *Depth* - Contains depth data, providing the distance of surfaces from a point of view.

- **Valid**
  - *RGB* - RGB data for validation.
  - *Depth* - Depth data for validation.

- **Test**
  - *Test-STU* - Consistent scene settings with the training set.
  - *Test-ITW* - Green screens are removed and replaced with dynamic or static backgrounds.
  - *Test-SYN* - Synthesize indoor and outdoor backgrounds.
  - *Test-TED* - Randomly adjusting video segments.
    - *RGB* - RGB data for testing.
    - *Depth* - Depth data for testing.




<!-- # Test 2 -->


